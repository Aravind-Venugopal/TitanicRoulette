{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import dill\n",
    "\n",
    "import mummify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/stars.csv')\n",
    "df = df[df['repo'] != 'maxhumber/gazpacho']\n",
    "df = df[df.language.isin(['Python', 'Jupyter Notebook'])]\n",
    "popular = pd.DataFrame(df['repo'].value_counts())\n",
    "select_repos = popular[popular['repo'] >= 5].index.tolist()\n",
    "df = df[df['repo'].isin(select_repos)]\n",
    "df = df.groupby(['user'])['repo'].apply(lambda x: ','.join(x))\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNRecommender:\n",
    "    def __init__(self, n_neighbors=10, max_features=1000, tokenizer=lambda x: x.split(\",\")):\n",
    "        self.cv = CountVectorizer(tokenizer=tokenizer, max_features=max_features)\n",
    "        self.nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        X = self.cv.fit_transform(X)\n",
    "        self.nn.fit(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xp = []\n",
    "        for Xi in X:\n",
    "            Xt = self.cv.transform([Xi])\n",
    "            _, neighbors = self.nn.kneighbors(Xt)\n",
    "            repos = []\n",
    "            for n in neighbors[0]:\n",
    "                r = self.X.iloc[int(n)].split(\",\")\n",
    "                repos.extend(r)\n",
    "            repos = list(set(repos))\n",
    "            repos = [r for r in repos if r not in Xi.split(\",\")]\n",
    "            Xp.append(repos)\n",
    "        return Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NNRecommender at 0x120b6bac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 10\n",
    "max_features = 1000\n",
    "\n",
    "model = NNRecommender(n_neighbors, max_features)\n",
    "model.fit(df['repo'])\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    dill.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['shengqiangzhang/examples-of-web-crawlers',\n",
       "  'mherrmann/fbs',\n",
       "  'PySimpleGUI/PySimpleGUI',\n",
       "  'scikit-learn/scikit-learn',\n",
       "  'donnemartin/system-design-primer',\n",
       "  'fastai/fastai',\n",
       "  'sloria/TextBlob',\n",
       "  'plasticityai/supersqlite',\n",
       "  'minimaxir/big-list-of-naughty-strings',\n",
       "  'TheAlgorithms/Python',\n",
       "  'ytdl-org/youtube-dl',\n",
       "  'vinta/awesome-python',\n",
       "  'Avik-Jain/100-Days-Of-ML-Code']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mummify.log(f'')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
